Datasets of sizes: 
1. actual sizes of background and class present in each image
2. 10 bins, where each object of each class is put in a bin based on the % of image they take up
3. 50% background, and 50% spread out amongst the classes present

Loss functions used:
1. Sal_loss: from the paper
2. Class_loss: from the paper
3. Size_loss: loss functions I implemented. There are 2 size loss functions:
			  Size_loss_1: (t_i^n - size_i^n)^2 
			  Size_loss_2: penalty loss function. penalize if t_i^n is less than a or greater than b
			  For the exact loss function equations, please refer to Loss 1 and Loss 2 here: http://sharhadbashar.com/HTML/mastersThesis.html

Tests:
1.  Sal_loss + Size_loss_1 on dataset 1
2.  Sal_loss + class_loss + Size_loss_1 on dataset 1

3.  Sal_loss + Size_loss_1 on dataset 2 0.5804
4.  Sal_loss + Class_loss + Size_loss_1 on dataset 2 This gave the bext result at miou = 0.6008

5.  Sal_loss + Size_loss_1 on dataset 3 miou = 0.4714
6.  Sal_loss + Class_loss + Size_loss_1 on dataset 3 miou = 0.5023

7.  Sal_loss + Size_loss_2 on dataset 1
8.  Sal_loss + Class_loss + Size_loss_2 on dataset 1 

9.  Sal_loss + Size_loss_2 on dataset 2 
10. Sal_loss + Class_loss + Size_loss_2 on dataset 2 0.5855

11. Sal_loss + Size_loss_2 on dataset 3
12. Sal_loss + Class_loss + Size_loss_2 on dataset 3 0.4826

13. Sal_loss + Class_loss + Size_loss_1 on dataset 3, recomputing size after every 2 epoch miou = 0.5328
14. Sal_loss + Class_loss + Size_loss_1 on dataset 3, recomputing size after every 1 epoch miou = 0.5582
15. Sal_loss + Class_loss + Size_loss_1 on dataset 3, recomputing average size after every 1 epoch; new_size = (new_size + old_size) / 2 miou = 0.5456

16. Sal_loss + Class_loss + Size_loss_2 on dataset 3, recomputing size after every 1 epoch, where a and b are dynamic miou = 0.5423
17. Sal_loss + Class_loss + Size_loss_2, recomputing size after every 1 epoch, where a and b are static at a = 0.15 and b = 1 miou = 0.1187

18. Sal_loss + Size_loss_2, where a and b are static at a = 0.15 and b = 1 miou = 0.0982
19. Sal_loss + Class_loss + Size_loss_2, where a and b are static at a = 0.15 and b = 1 miou = 0.1955





a = 0.15, b = 1
learning rate = 1e-5
weight = 1
validation: iter 15000; miou 0.4897; best 12000:0.4930
[0.24194236504953603, 0.37468653281050296, 0.4410833633922528, 0.47891683584619404, 0.4830790669473962, 0.48226762164012577, 0.4871190563307539, 0.4910144576178676, 0.4854053860380327, 0.4921852437474179, 0.48938841717509585, 0.49058670055154674, 0.49010094078446526, 0.48993413993152696, 0.48870144230394913, 0.48850096616044153, 0.48825780116908085, 0.492038994284452, 0.4921726217476077, 0.4907835980948557, 0.4878052542938472, 0.49028636238163503, 0.4870661902331917, 0.49303753724837535, 0.4875465303278977, 0.490328824059975, 0.4926795108226271, 0.4901466009756752, 0.4902364902935893, 0.4896782565514917]
train: 125it [00:10, 11.66it/s]
mae 0.0789; best 12500:0.0772
fm 0.8491; best 12500:0.8513

learning rate = 1e-5
weight = 10
validation: iter 15000; miou 0.4419; best 10000:0.4504
[0.22105128691495257, 0.38394878952783446, 0.4243838493191398, 0.4411178151869974, 0.4444731135939393, 0.4443265204571635, 0.44176094824949513, 0.44536794750212283, 0.4414727670275318, 0.44135221852775264, 0.43917524862533514, 0.4485668126755651, 0.4407330414288928, 0.4436959527756115, 0.4421716526611461, 0.44753272935516797, 0.44290251136857295, 0.4375481923403535, 0.4478903714444272, 0.4503588984919632, 0.4490108222610668, 0.4458702190276923, 0.4426216782457993, 0.44138648845496276, 0.44615662795932887, 0.4444652271615329, 0.44809123565618847, 0.43821955651898764, 0.4452873195970047, 0.4418609528857244]
train: 125it [00:13,  9.11it/s]
mae 0.1294; best 10500:0.1151
fm 0.8557; best 9500:0.8603

learning rate = 1e-5
weight = 20
validation: iter 15000; miou 0.3232; best 1500:0.3431
[0.1860635860316766, 0.3143274692474875, 0.3431314034370536, 0.3332600919526375, 0.3299684841566042, 0.32899301960689487, 0.3229673414163405, 0.3316264739459669, 0.3163051637177238, 0.3190454787362399, 0.32217008529948815, 0.3277457316042431, 0.3112386585947153, 0.31512639664714115, 0.3184241496548715, 0.31005087288762334, 0.323005190845966, 0.309767022151703, 0.32012890411611206, 0.31269638949499773, 0.3147527929506522, 0.3210545584193452, 0.31970912340450114, 0.30481645382028855, 0.3165585397238213, 0.31789417385564683, 0.3270810960405279, 0.3151573845168606, 0.3215627836676764, 0.3231698278882008]
train: 125it [00:14,  8.34it/s]
mae 0.2447; best 1500:0.2012
fm 0.8502; best 11000:0.8520

learning rate = 1e-5
weight = 50
validation: iter 15000; miou 0.2324; best 9500:0.2374
[0.14585772642286954, 0.19269135503709897, 0.2074371940313642, 0.2360769132051843, 0.2363531162553172, 0.23321870726214944, 0.23176413154897196, 0.23118281540114696, 0.23088929918853457, 0.22439893991145135, 0.23241511755128816, 0.2269856087002329, 0.21298032188164823, 0.22937277015367644, 0.22318664126856538, 0.22394774096733525, 0.22813774783054344, 0.23116999650192968, 0.2373641619927542, 0.22891203227423118, 0.23169598742114492, 0.22414666587755758, 0.2229573496934614, 0.2294445293921603, 0.2244222401661723, 0.22881990342086164, 0.22703933727576958, 0.22485068434743052, 0.22474490159676938, 0.23239813486837202]
train: 125it [00:15,  8.20it/s]
mae 0.2122; best 6500:0.1617
fm 0.8392; best 10500:0.8437

learning rate = 1e-4
weight = 1
validation: iter 15000; miou 0.5284; best 14500:0.5311
[0.46627108852708216, 0.4782286131271761, 0.4883787731918838, 0.4769310558984428, 0.5124143709883401, 0.5188554346541077, 0.5176819955505364, 0.524806174487801, 0.5251647434264639, 0.5273350682276087, 0.5256853380619445, 0.5209973981022045, 0.5283432091589466, 0.5301798583926324, 0.5275448825597145, 0.5297336512944932, 0.528385420936853, 0.5230878484661307, 0.5283339617390304, 0.5273310913212583, 0.5262071336265502, 0.5267922277149613, 0.5274810704971278, 0.5269134114998177, 0.5258032137918626, 0.5301178116829524, 0.5267897483396534, 0.5247959051752741, 0.5311144034060137, 0.5283698150974742]
train: 125it [00:10, 12.09it/s]
mae 0.0551; best 5500:0.0541
fm 0.8839; best 5500:0.8871

learning rate = 1e-4
weight = 10
validation: iter 15000; miou 0.2616; best 500:0.3494
[0.3494480537416205, 0.3312422444906749, 0.2916739791416238, 0.29383868175360633, 0.25960152929567143, 0.2877272455482068, 0.28622356873903004, 0.2560358219788407, 0.2604312386050297, 0.2481731417504624, 0.2628780435804896, 0.2664031308679202, 0.26522793624282165, 0.2622433450429412, 0.27067033833738563, 0.2643442474000784, 0.2686800622026105, 0.26966569944788416, 0.2723498960145941, 0.26329483483469457, 0.27058695180032355, 0.2441169476261701, 0.27854396861128405, 0.26863358323042674, 0.27206962299906357, 0.2633752953772719, 0.24772790939619124, 0.2764300071574381, 0.2675064693718387, 0.2615502791275829]
train: 125it [00:14,  8.39it/s]
mae 0.1932; best 2000:0.0711
fm 0.8293; best 3000:0.8521

learning rate = 1e-4
weight = 20
validation: iter 2000; miou 0.0849; best 500:0.1553
[0.15528473349491287, 0.1212403745156058, 0.09998122522467359, 0.08487869526279318]
train: 125it [00:11, 10.45it/s]
mae 0.0797; best 1500:0.0792
fm 0.8459; best 1500:0.8592

learning rate = 1e-4
weight = 50
validation: iter 15000; miou 0.0697; best 500:0.1460
[0.14604785529405917, 0.09644070022762584, 0.07797136933595153, 0.07173051300645433, 0.07149136529214146, 0.07056736328090904, 0.07240762614192031, 0.07023090819251897, 0.07037354000600837, 0.07121805955115564, 0.07256580305529388, 0.06957891047393557, 0.07001155827385294, 0.07169994903537907, 0.06974484214776702, 0.07317388062700962, 0.07084401279745682, 0.06957525712176103, 0.07249186055085435, 0.07002134554137475, 0.07132888362540286, 0.07020565868450006, 0.07140441872389247, 0.07150136678932557, 0.0701681978715201, 0.07051743566160876, 0.0706154322762034, 0.07129433828718817, 0.07064621779540362, 0.06974067914004356]
train: 125it [00:13,  9.54it/s]
mae 0.0829; best 8000:0.0768
fm 0.8538; best 7000:0.8578

learning rate = 1e-3
weight = 1
validation: iter 15000; miou 0.2375; best 9000:0.2434
[0.10859020044966561, 0.13443992294937998, 0.1594187001325602, 0.14750045072169168, 0.20637438382298798, 0.21743832900762974, 0.23044298264656776, 0.22905176519379372, 0.23781274108554243, 0.23563354950760948, 0.23722190073645646, 0.24001560466421945, 0.23723147381038706, 0.23676684069358472, 0.240036162725097, 0.23607371104284378, 0.23839532551876802, 0.24335963795294271, 0.23925984024402447, 0.2363931924227676, 0.23629729616327816, 0.2415199039107861, 0.23825924252351002, 0.24203293766448944, 0.23812761373765054, 0.2403993218419855, 0.2386450401956691, 0.24127583676096645, 0.23878568307641035, 0.23749200015766553]
train: 125it [00:10, 11.81it/s]
mae 0.0647; best 5500:0.0632
fm 0.8620; best 5500:0.8660

learning rate = 1e-3
weight = 10
validation: iter 15000; miou 0.0655; best 500:0.0908
[0.09082932793998195, 0.06958092491855562, 0.056498650015552716, 0.05821959463947604, 0.06747055926420749, 0.0602963870556997, 0.06707399326324885, 0.069727594903756, 0.06183014118736785, 0.06223341018308485, 0.06573044339884755, 0.0681340197941365, 0.06764161741552563, 0.061652664893510956, 0.0628936055945591, 0.06773626819358287, 0.06450290761748594, 0.060058695771369734, 0.06746913070154109, 0.06423014058898334, 0.06461423745240916, 0.0676708856820988, 0.06052362770121994, 0.06235421838811141, 0.06860236270823934, 0.058203561129727376, 0.06055244737767614, 0.0638575915964218, 0.06422022459643431, 0.06547665530900651]
train: 125it [00:12, 10.30it/s]
mae 0.1264; best 2500:0.0851
fm 0.7897; best 2500:0.8072

learning rate = 1e-3
weight = 20
train: 182it [00:16, 11.33it/s]
validation: iter 7000; miou 0.0533; best 500:0.0603
[0.060258638053962414, 0.051913289453410186, 0.05444859450277088, 0.04746856470219759, 0.04891535940505255, 0.053458040273005644, 0.0490811909732109, 0.058019622848993854, 0.05474951724290788, 0.05903654551007044, 0.0569166608016768, 0.05686209868889644, 0.056036712762661714, 0.0533184348986406]
train: 125it [00:12, 10.18it/s]
mae 0.1832; best 5000:0.0977
fm 0.7521; best 5000:0.7892




with new loss 3_3
before
learning rate = 1e-4
weight = 1
validation: iter 15000; miou 0.5284; best 14500:0.5311
[0.46627108852708216, 0.4782286131271761, 0.4883787731918838, 0.4769310558984428, 0.5124143709883401, 0.5188554346541077, 0.5176819955505364, 0.524806174487801, 0.5251647434264639, 0.5273350682276087, 0.5256853380619445, 0.5209973981022045, 0.5283432091589466, 0.5301798583926324, 0.5275448825597145, 0.5297336512944932, 0.528385420936853, 0.5230878484661307, 0.5283339617390304, 0.5273310913212583, 0.5262071336265502, 0.5267922277149613, 0.5274810704971278, 0.5269134114998177, 0.5258032137918626, 0.5301178116829524, 0.5267897483396534, 0.5247959051752741, 0.5311144034060137, 0.5283698150974742]
train: 125it [00:10, 12.09it/s]
mae 0.0551; best 5500:0.0541
fm 0.8839; best 5500:0.8871

after
train: 182it [00:15, 11.86it/s]
validation: iter 91500; miou 0.5397; best 29000:0.5428
[0.4658330845340812, 0.48944545257019767, 0.5311813946445398, 0.48771891456148997, 0.520234300961827, 0.5223835181104728, 0.5319130940725361, 0.5369619851534667, 0.5335023236295131, 0.5370659258450778, 0.534143822526024, 0.5381080895362363, 0.5359103870349406, 0.5383729368554774, 0.5372288623831653, 0.538521107280143, 0.5384229149666685, 0.5375295378858118, 0.5394543368117853, 0.538960287350117, 0.537718178795715, 0.5363470015041083, 0.5367165045131329, 0.5369429968644143, 0.5377932662602831, 0.5387759998233379, 0.536978638933489, 0.5376436931296302, 0.535947705247616, 0.5390617510294692, 0.5388798566801415, 0.5361943542045237, 0.5349453902272912, 0.5374715542465474, 0.5363986092446706, 0.5395925564615187, 0.5361885646143199, 0.5382309686041208, 0.5394920270768184, 0.5386915874704591, 0.5377073697764704, 0.5375408831525255, 0.5383342044254564, 0.53587538539115, 0.5374807674230282, 0.5382669057365173, 0.5385020458859199, 0.5392946115195739, 0.5371684621328322, 0.5352545510730174, 0.5382994090487984, 0.536854610047684, 0.5394894457449732, 0.5356292769685179, 0.541928882387417, 0.5367333510424073, 0.5371828678243945, 0.5427505109403186, 0.5375296139016166, 0.5391430383239333, 0.5381685379570313, 0.540955452031762, 0.5382886413661423, 0.5385023436512475, 0.5372628829209558, 0.5366152781587191, 0.538168130586894, 0.5379719780704307, 0.5373787385828358, 0.5398608857532194, 0.5367155585775153, 0.5402305804715412, 0.5388117278448837, 0.5347858097314534, 0.5351717515744655, 0.539196083748636, 0.5387687402696095, 0.5385927826862998, 0.5380073298860643, 0.5378351171764673, 0.540435193831419, 0.5368160761596731, 0.5375765461687988, 0.5355978974552575, 0.5402844809274298, 0.5369437526678434, 0.5397643669854715, 0.5373922971142774, 0.5360061475004739, 0.5375563521333915, 0.5357187573521396, 0.5353510344392092, 0.5344198202262629, 0.5379094669817248, 0.5337946356867516, 0.5359251579876103, 0.5406617591187712, 0.5395030677460529, 0.5385553527564809, 0.5413799822132693, 0.5377157435317698, 0.537466178095971, 0.5383856933292561, 0.5381381004101625, 0.5359548085417026, 0.537744426420752, 0.5382118499475872, 0.5396044904174119, 0.538031444604977, 0.536364737357786, 0.5406035857946161, 0.536330938091343, 0.5394884844763188, 0.5377095530931264, 0.5352631020216294, 0.5403460095089142, 0.5352640246125231, 0.5369938904263188, 0.539197791306517, 0.5342740418421464, 0.5395700381437832, 0.5365492307317724, 0.5374979022480803, 0.5385183461036096, 0.5395337196187922, 0.5400049168661617, 0.5396945486969286, 0.5374077556551219, 0.5391969225188061, 0.5390015813071708, 0.5369085816376211, 0.5377323147674241, 0.537042673786802, 0.5354055514093831, 0.5374736776378372, 0.5375595261338775, 0.5391952712584118, 0.5391148786480211, 0.5406573246197997, 0.5373679271609165, 0.5378376375500755, 0.5395836465877787, 0.540154051042744, 0.5361941248460125, 0.539232937552097, 0.5357449424547914, 0.5360303129822944, 0.5372829964682341, 0.5375754125620211, 0.5385070448154691, 0.5386232451618272, 0.5386371304771297, 0.5374810297882705, 0.5402010053642484, 0.5387153231178051, 0.5379223719057522, 0.5344177487749587, 0.5370737967163767, 0.5392336109420462, 0.5353538684489214, 0.5359492872616686, 0.5390435955229945, 0.5357337238472601, 0.5390548865996625, 0.5369118617970708, 0.5356913169189191, 0.5411428311512281, 0.5380509281107398, 0.5351491289578507, 0.5404603006605343, 0.5406584376704257, 0.5368309155507761, 0.5379161651520484, 0.5365777878214519, 0.5383154956796848, 0.5355662557776247, 0.5396001549851379, 0.5416542878247822, 0.5375288708813388, 0.5403383069049207, 0.5368875478515152, 0.5377461796683266, 0.5397136254791082]
train: 125it [00:11, 11.21it/s]
mae 0.0577; best 40500:0.0559
fm 0.8791; best 33000:0.8866


loss 3_3
learning rate = 1e-4
weight = 1e-4 for for 3_3
weight = 1 for 3_2
train: 182it [00:15, 11.63it/s]
validation: iter 34500; miou 0.5370; best 20000:0.5409
[0.4780615562315915, 0.45579471271631017, 0.4881098722379431, 0.4702969744538451, 0.5210533171676363, 0.5353010316999636, 0.5340551681938491, 0.5320818338162299, 0.53305064506939, 0.5365319539194717, 0.5348745838472676, 0.5364412054409612, 0.5351284297619188, 0.536792795979594, 0.5386916407109957, 0.5405074804719109, 0.5373535991032578, 0.537606760778596, 0.5372772471015475, 0.5375403987114017, 0.5354581504259586, 0.5391579568516419, 0.5341444963350617, 0.5352270200552984, 0.536095806397259, 0.5357454711830294, 0.5401491067872237, 0.5374721623455883, 0.5363732363016208, 0.5362275444800395, 0.5366517218046695, 0.535000886383669, 0.5386289669611837, 0.536428702610401, 0.539008525262374, 0.5389575061370573, 0.5363234491723661, 0.5402601033967503, 0.5364203475062203, 0.5409305492765422, 0.5401992004118477, 0.5371093078282401, 0.5384620571241483, 0.5397153128091078, 0.5349315437764844, 0.5404656685270398, 0.5372335314866, 0.5349083496558236, 0.540493676591644, 0.5350165455780364, 0.5400930856688839, 0.537699121061617, 0.5387102857466729, 0.5355951336354706, 0.5350849774571588, 0.5374716856124279, 0.5377221568707835, 0.5361236259334748, 0.5329857770641014, 0.5390118948544896, 0.5341373609759894, 0.5338052900199822, 0.5380634360782358, 0.5402521037926936, 0.5374096673212178, 0.535180288416436, 0.5378759340714405, 0.5369138249558405, 0.5369547396837226]
train: 125it [00:10, 12.11it/s]
mae 0.0546; best 22000:0.0525
fm 0.8841; best 22000:0.8913

loss 3_3
learning rate = 1e-4
weight = 1e-3 for for 3_3
weight = 1 for 3_2
train: 182it [00:14, 12.18it/s]
validation: iter 34500; miou 0.5346; best 21500:0.5392
[0.4395481976089637, 0.46236724511260746, 0.5052630591354522, 0.4770133346821082, 0.5155273296156154, 0.522553848760352, 0.5277023766276561, 0.5301820919118301, 0.5347520072898699, 0.5339435914946311, 0.533587642356492, 0.5334541709826313, 0.5335682245261565, 0.5313518688643001, 0.5359690510438673, 0.532846918749263, 0.5301091445337942, 0.5349878081765658, 0.5336509224984939, 0.5308564504496898, 0.5343231554161807, 0.5354791761714398, 0.5330454965750624, 0.5316101223430283, 0.5384986052076303, 0.5379447815720538, 0.5351265207925335, 0.5321647277554652, 0.5338353494815342, 0.5288764334783316, 0.5362938083974418, 0.5359985083183366, 0.5362977407808827, 0.531848321458201, 0.532388551796925, 0.5344514629584233, 0.5343326746853441, 0.5344117100673655, 0.5340431387074617, 0.5339460776377373, 0.532764300068868, 0.5321122391542584, 0.5392230736620245, 0.5351455479053443, 0.535618196197732, 0.53692761179648, 0.5335520581616731, 0.5298736948747814, 0.5345821586489098, 0.5340998653986528, 0.5361900035850311, 0.5342556624291669, 0.5333682485449597, 0.5285774183753719, 0.5346646650421333, 0.5348804987337648, 0.5348957534642887, 0.5316925188571868, 0.5326224432622461, 0.5336217325505919, 0.5346507790961295, 0.5364103512591668, 0.5300419815297311, 0.5357286401583141, 0.5347201723048833, 0.5363548125259656, 0.5319360401980544, 0.5326871183234316, 0.5345848372473772]
train: 125it [00:10, 12.26it/s]
mae 0.0531; best 32000:0.0522
fm 0.8873; best 33000:0.8908

loss 3_3
learning rate = 1e-4
weight = 1e-2 for for 3_3
weight = 1 for 3_2
train: 182it [00:15, 11.65it/s]
validation: iter 34500; miou 0.5333; best 18500:0.5427
[0.4676235585981426, 0.4558452311005459, 0.4703013321773768, 0.4905571076759827, 0.5181604877738452, 0.5271930432529567, 0.5299627889138646, 0.5313511621992868, 0.5331056238658172, 0.5343100231284046, 0.53586979691517, 0.5354315808569848, 0.5333888321932145, 0.5328452652494841, 0.5329515405919644, 0.5344211301153854, 0.5323322163743394, 0.5314605997846817, 0.5326693073527766, 0.5378787108332601, 0.5398128504146735, 0.5385972805644197, 0.5376338411009567, 0.5333402295564711, 0.5351455815977391, 0.5370153163363272, 0.5368591738513736, 0.5391900298536444, 0.536049577608278, 0.5326603218645818, 0.5382916333912563, 0.5332535728644993, 0.5340340908254776, 0.5344174711540918, 0.5350937594845254, 0.5365262900909796, 0.5426737578739185, 0.5371156197647947, 0.5353104924258957, 0.5377219248829179, 0.5358957714534766, 0.5367725901163548, 0.5382420451594383, 0.536805097836087, 0.5351139453917773, 0.5363149248847617, 0.5354553556221837, 0.5341049832967552, 0.5346402690493809, 0.5382696009459238, 0.5371375059720411, 0.5338358803876169, 0.535841051180413, 0.5376270369525809, 0.5376207726780312, 0.5373924297357087, 0.5337073577041161, 0.5316287635062616, 0.5352783312945141, 0.537423682926461, 0.5414634068819896, 0.5373781938267961, 0.5375725813825531, 0.536401058818047, 0.5341568646992388, 0.5384939527221732, 0.5375097944816236, 0.5334283107804184, 0.5332686030356387]
train: 125it [00:10, 11.92it/s]
mae 0.0567; best 8500:0.0545
fm 0.8835; best 4000:0.8875



loss 3_3
train: 182it [00:15, 11.86it/s]
validation: iter 34500; miou 0.5578; best 24500:0.5594
[0.4577496790846486, 0.47566989176387414, 0.5081659393754712, 0.504539163068638, 0.5386667797289035, 0.5479899162996359, 0.5464641498851817, 0.5555692765943709, 0.5570323491795113, 0.5565773485957322, 0.5583855464034381, 0.5523117732947926, 0.5560278648329396, 0.5548682264457441, 0.5559026143597878, 0.5588390153567612, 0.5572207026014566, 0.5572502770320656, 0.5528302865234177, 0.5588509703559438, 0.5572554772824624, 0.559350456259936, 0.556393744583387, 0.5564948087139276, 0.5571501785237338, 0.5568754540691734, 0.5562655291043981, 0.5550873052047478, 0.555086237239447, 0.5537638361361198, 0.5557012048087796, 0.5592839281270378, 0.5573996008968216, 0.5555360989655175, 0.5583658953047392, 0.5575721695672394, 0.5586361664442723, 0.556716249210766, 0.5564334606893792, 0.5573335676487755, 0.5557228487419879, 0.5573485071249633, 0.557882749984172, 0.5518124073486693, 0.5577408759375, 0.5582724436533759, 0.5540772212810156, 0.557349318244106, 0.5593954198497643, 0.5555219873056052, 0.5573670578049921, 0.5590775491636127, 0.5553550924387933, 0.5564829956419642, 0.5557469097973409, 0.5545789963893045, 0.5561539114930284, 0.5576219630041903, 0.5543609889940571, 0.556807667435242, 0.555554055975285, 0.556469859644824, 0.5569210643075375, 0.555443086588843, 0.5549362926276237, 0.552007421659292, 0.5567033456724458, 0.5568021017081238, 0.5577650110247753]
train: 125it [00:10, 12.24it/s]
mae 0.0533; best 33000:0.0522
fm 0.8880; best 33000:0.8914

